{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonYen-tw/CNN-Assignment-2025/blob/main/ACS111147_CNN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "036f1c8c",
      "metadata": {
        "id": "036f1c8c"
      },
      "source": [
        "# ACS111147 - CNN 卷積神經網路實作 (CIFAR-10)\n",
        "\n",
        "## 專案描述\n",
        "\n",
        "這個專案的目標是在 CIFAR-10 數據集上訓練一個卷積神經網路（CNN）。CIFAR-10 包含 10 個類別的 32x32 彩色圖片，分別是：飛機、汽車、鳥、貓、鹿、狗、青蛙、馬、船和卡車。\n",
        "\n",
        "## 實作重點\n",
        "1.  **模型架構**：採用一個包含多個卷積層、LeakyReLU 激活函數、MaxPooling 和 Dropout 的深度 CNN 模型。\n",
        "2.  **資料預處理**：將圖片像素值標準化到 [-0.5, 0.5] 區間，並對標籤進行 One-Hot 編碼。\n",
        "3.  **資料增強 (Data Augmentation)**：使用 `ImageDataGenerator` 對訓練圖片進行即時的隨機旋轉、平移和水平翻轉，以提高模型的泛化能力。\n",
        "4.  **模型訓練**：使用 Adamax 優化器和一個學習率排程器（Learning Rate Scheduler）來動態調整學習率，以達到更好的收斂效果。\n",
        "5.  **自動化評分**：訓練完成後，模型會評估其在測試集上的表現，並將準確率、損失值等關鍵指標寫入 `model_accuracy.txt` 檔案中，以供 GitHub 自動化評分系統讀取。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4117cbb5",
      "metadata": {
        "id": "4117cbb5"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Keras Version:\", keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b4ac39",
      "metadata": {
        "id": "05b4ac39"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "print(\"訓練資料維度:\", x_train.shape, y_train.shape)\n",
        "print(\"測試資料維度:\", x_test.shape, y_test.shape)\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "cols = 8\n",
        "rows = 2\n",
        "plt.figure(figsize=(2 * cols, 2.5 * rows))\n",
        "for i in range(cols * rows):\n",
        "    random_index = np.random.randint(0, len(y_train))\n",
        "    ax = plt.subplot(rows, cols, i + 1)\n",
        "    ax.imshow(x_train[random_index, :])\n",
        "    ax.set_title(class_names[y_train[random_index, 0]])\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f389dc6c",
      "metadata": {
        "id": "f389dc6c"
      },
      "outputs": [],
      "source": [
        "x_train_norm = (x_train / 255.0) - 0.5\n",
        "x_test_norm = (x_test / 255.0) - 0.5\n",
        "\n",
        "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "print(\"標準化後訓練圖片維度:\", x_train_norm.shape)\n",
        "print(\"One-Hot 編碼後訓練標籤維度:\", y_train_cat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3d25ee",
      "metadata": {
        "id": "fa3d25ee"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (3, 3), input_shape=(32, 32, 3), padding='same'))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b3a9a",
      "metadata": {
        "id": "ac9b3a9a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "INIT_LR = 5e-3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adamax(learning_rate=INIT_LR),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return INIT_LR * 0.9 ** epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90925d3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90925d3b",
        "outputId": "9c256719-8ada-4c0a-d546-40f999681c9d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1288/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 125ms/step - accuracy: 0.3672 - loss: 1.7205"
          ]
        }
      ],
      "source": [
        "train_generator = data_generator.flow(x_train_norm, y_train_cat, BATCH_SIZE)\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[LearningRateScheduler(lr_scheduler)],\n",
        "    validation_data=(x_test_norm, y_test_cat),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed96332",
      "metadata": {
        "id": "8ed96332"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test_norm, y_test_cat, verbose=2)\n",
        "\n",
        "try:\n",
        "    with open('model_accuracy.txt', 'w') as f:\n",
        "        f.write(\"Model Performance Summary:\\n\")\n",
        "        f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
        "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
        "        f.write(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\\n\")\n",
        "        f.write(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\\n\")\n",
        "        f.write(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\\n\")\n",
        "        f.write(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\\n\")\n",
        "        f.write(f\"Training Epochs: {len(history.history['accuracy'])}\\n\")\n",
        "        f.write(f\"Model Parameters: {model.count_params()}\\n\")\n",
        "\n",
        "    with open('model_accuracy.txt', 'r') as f:\n",
        "        print(\"\\n--- Content of model_accuracy.txt ---\")\n",
        "        print(f.read())\n",
        "except Exception as e:\n",
        "    print(f\"Error writing to file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91639c08",
      "metadata": {
        "id": "91639c08"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2ef45e",
      "metadata": {
        "id": "5d2ef45e"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test_norm)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "cols = 8\n",
        "rows = 2\n",
        "plt.figure(figsize=(2 * cols, 3 * rows))\n",
        "for i in range(cols * rows):\n",
        "    random_index = np.random.randint(0, len(y_test))\n",
        "    ax = plt.subplot(rows, cols, i + 1)\n",
        "    ax.imshow(x_test[random_index, :])\n",
        "    pred_label = class_names[predicted_labels[random_index]]\n",
        "    true_label = class_names[y_test[random_index, 0]]\n",
        "    title_color = 'g' if pred_label == true_label else 'r'\n",
        "    ax.set_title(f\"Pred: {pred_label}\\nTrue: {true_label}\", color=title_color)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}